{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d100bb8",
   "metadata": {},
   "source": [
    "Get all movies from the Bechdel dataset, containing Title, IMDb id's, year of release and the Bechdel-test scores. \n",
    "Called via the API, it's a little too easy. If we wanted to know more about the submitters and comments, we could use the more elaborate calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bechdel_films = pd.read_json('http://bechdeltest.com/api/v1/getAllMovies') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8ae46",
   "metadata": {},
   "source": [
    "Write it into a csv, so we won't screw up with the Bechdel API curators. They kindly ask us to cache and not call the getAllMovies too often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab65042",
   "metadata": {},
   "outputs": [],
   "source": [
    "bechdel_films.to_csv('data/bechdel_films.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "bechdel_films = pd.read_csv('data/bechdel_films.csv' , dtype = str) #read as sting, otherwise our prescious imdb id's are float types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98500c63",
   "metadata": {},
   "source": [
    "First, let's get the tags/keywords to figure out which film is LGBTQ+ related.  \n",
    "We scrape every film that is in the Bechdel-test dataset.  \n",
    "Save the full lists of tags into a dictionary by IMDb id's for later use.  \n",
    "Later scraping steps are also going to be saved into dics by IMDb id's, so we can join them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in bechdel_films['imdbid']:\n",
    "    try: \n",
    "        res = requests.get(\"https://www.imdb.com/title/tt\" + i + \"/keywords?ref_=tt_stry_kw\")\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        taglist = soup.find_all('div' , class_=\"sodatext\")\n",
    "        tag_dict[i] = [ j.text.strip('\\n') for j in taglist ]\n",
    "        j = j + 1 \n",
    "    except (ConnectionError , TypeError) as err: \n",
    "        #if there is a connection or type error, then print error msg it with the ID, so the code doesn't get interrupted.\n",
    "        print(err + \": IMDb ID:\" + i )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade067a",
   "metadata": {},
   "source": [
    "Save our precious dictionary into a file, then load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc38f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/tag_dictionary.npy', tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = np.load('data/tag_dictionary.npy', allow_pickle = True ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01625fac",
   "metadata": {},
   "source": [
    "Let's define our LGBTQ keywords.    \n",
    "By checking if a film is LGBTQ+ related, we iterate through the tags/keywords scraped from IMDb and check how many of the keywords (cleaned from punctiation, special characters) is in the the LGBTQ+ keyword list.  \n",
    "We save it into a dataframe, with following columns: IMDb ID (for joins), number of keywords scraped, number of LGBTQ+ keyword spotted.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbtq_keywords = [ 'lgbt' , 'lgbtq' ,\n",
    "                  'gay' , 'gays' , 'gaycharacter' , 'gaykiss' , 'gayinterest' , \n",
    "                  'lesbian' , 'lesbians' , 'lesbianinterest' , \n",
    "                  'queer' , \n",
    "                  'trans' , 'transsexual' , 'transwoman' , 'transman' , 'transgender' , \n",
    "                  'bisexual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f00340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "for k,v in tag_dict.items():\n",
    "    isitgay = sum([ (re.sub( r'\\W+', '', vv) in lgbtq_keywords) for vv in v] )\n",
    "    df_rows.append( [ k , isitgay , len(v) ] )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "gay_df = pd.DataFrame(df_rows, columns = ['imdbid','lgbtq_keywords_num','keywords_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge( bechdel_films , gay_df , how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc851221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df['lgbtq_keywords_num']  > 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44178e87",
   "metadata": {},
   "source": [
    "df.to_csv('data/bechdel_films_ifgay.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bechdel_films_ifgay.csv' , dtype = str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d286a",
   "metadata": {},
   "source": [
    "We read everything as string, some columns are numeric, so let's transform them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd47515",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['year' , 'rating' , 'lgbtq_keywords_num' , 'keywords_num']\n",
    "\n",
    "for i in numeric_cols:\n",
    "    df[i] = pd.to_numeric(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.imdbid.notnull()].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6aa2b",
   "metadata": {},
   "source": [
    "### Use the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_keys = ['7ecc3518' , \n",
    "           'efbb5d26' , \n",
    "           '101156d4' , \n",
    "           '78906128' , \n",
    "           'c0bebd87']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_json_dict = np.load('data/movie_data_dict.npy', allow_pickle = True ).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c485aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_imdb_ids = [e for e in df['imdbid'].to_list() if e not in list(resp_json_dict.keys()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imdb_id in list_of_imdb_ids:\n",
    "    try:\n",
    "        url = 'http://www.omdbapi.com/?i=tt' + imdb_id + '&apikey=' + API_keys[0]\n",
    "        resp = requests.get(url)        \n",
    "        resp_json = json.loads(resp.text)\n",
    "        \n",
    "        #if we happen to run into API limit (1.000 calls per day) and the error is because of the limit,\n",
    "        # this chunk overwrites the API_keys list, drops the first key we are using until no limit issue\n",
    "        while (resp_json['Response'] == 'False' and resp_json['Error'] == 'Request limit reached!'):\n",
    "            API_keys = API_keys[1:]\n",
    "            url = 'http://www.omdbapi.com/?i=tt' + imdb_id + '&apikey=' + API_keys[0]\n",
    "            resp = requests.get(url)        \n",
    "            resp_json = json.loads(resp.text)    \n",
    "        #save the json response into our dictionary    \n",
    "        resp_json_dict[imdb_id] = resp_json\n",
    "    \n",
    "    #if we encounter any type of errors, let's just print it, so the code running for hours doesn't get interrupted.\n",
    "    #we can return to the missing IMDb Id's later if feeling so\n",
    "    except Exception as e: \n",
    "        print(\"For IMDb Id: \" + str(imdb_id))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/movie_data_dict.npy' , resp_json_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
